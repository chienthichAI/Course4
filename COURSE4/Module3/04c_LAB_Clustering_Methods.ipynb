{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"cognitiveclass.ai logo\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 4, Part c: Clustering Methods LAB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Methods Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This lab uses a dataset on wine quality. The data set contains various chemical properties of wine, such as acidity, sugar, pH, and alcohol. It also contains a quality metric (3-9, with highest being better) and a color (red or white). The name of the file is `Wine_Quality_Data.csv`.\n",
    "\n",
    "We will be using the chemical properties (i.e. everything but quality and color) to cluster the wine. Though this is unsupervised learning, there are interesting semi-supervised extensions relating clustering results onto color and quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import seaborn as sns, pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "*   Import the data and examine the features.\n",
    "*   Note which are continuous, categorical, and boolean.\n",
    "*   How many entries are there for the two colors and range of qualities?\n",
    "*   Make a histogram plot of the quality for each of the wine colors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T12:10:48.585240Z",
     "start_time": "2017-03-20T08:10:48.548076-04:00"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "# BÀI TẬP 1: Khám phá dữ liệu về chất lượng rượu\n",
    "\n",
    "# Import dữ liệu từ CSV về chất lượng rượu vang\n",
    "# Dataset chứa các thuộc tính hóa học (acidity, pH, alcohol, ...) và chất lượng (3-9)\n",
    "data = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/Wine_Quality_Data.csv\")\n",
    "\n",
    "# Hiển thị 4 dòng đầu tiên với transpose để dễ quan sát\n",
    "data.head(4).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T12:09:58.538878Z",
     "start_time": "2017-03-20T08:09:58.531714-04:00"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data types for each entry. The implementation of K-means in Scikit-learn is designed only to work with continuous data (even though it is sometimes used with categorical or boolean types). Fortunately, all the columns we will be using (everything except quality and color) are continuous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T12:12:23.585637Z",
     "start_time": "2017-03-20T08:12:23.576416-04:00"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of entries for each wine color.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T12:10:32.347631Z",
     "start_time": "2017-03-20T08:10:32.337545-04:00"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "data.color.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of quality values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T13:00:49.509254Z",
     "start_time": "2017-03-20T09:00:49.495394-04:00"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "data.quality.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the histogram.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T13:05:20.809064Z",
     "start_time": "2017-03-20T09:05:20.584910-04:00"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# seaborn styles\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('white')\n",
    "\n",
    "# custom colors\n",
    "red = sns.color_palette()[2]\n",
    "white = sns.color_palette()[4]\n",
    "\n",
    "# set bins for histogram\n",
    "bin_range = np.array([3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "# plot histogram of quality counts for red and white wines\n",
    "ax = plt.axes()\n",
    "for color, plot_color in zip(['red', 'white'], [red, white]):\n",
    "    q_data = data.loc[data.color==color, 'quality']\n",
    "    q_data.hist(bins=bin_range, \n",
    "                alpha=0.5, ax=ax, \n",
    "                color=plot_color, label=color)\n",
    "    \n",
    "\n",
    "ax.legend()\n",
    "ax.set(xlabel='Quality', ylabel='Occurrence')\n",
    "\n",
    "# force tick labels to be in middle of region\n",
    "ax.set_xlim(3,10)\n",
    "ax.set_xticks(bin_range+0.5)\n",
    "ax.set_xticklabels(bin_range);\n",
    "ax.grid('off')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "*   Examine the correlation and skew of the relevant variables--everything except color and quality (without dropping these columns from our data).\n",
    "*   Perform any appropriate feature transformations and/or scaling.\n",
    "*   Examine the pairwise distribution of the variables with pairplots to verify scaling and normalization efforts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "float_columns = [x for x in data.columns if x not in ['color', 'quality']]\n",
    "\n",
    "# The correlation matrix\n",
    "corr_mat = data[float_columns].corr()\n",
    "\n",
    "# Strip out the diagonal values for the next step\n",
    "for x in range(len(float_columns)):\n",
    "    corr_mat.iloc[x,x] = 0.0\n",
    "    \n",
    "corr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Pairwise maximal correlations\n",
    "corr_mat.abs().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And an examination of the skew values in anticipation of transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "skew_columns = (data[float_columns]\n",
    "                .skew()\n",
    "                .sort_values(ascending=False))\n",
    "\n",
    "skew_columns = skew_columns.loc[skew_columns > 0.75]\n",
    "skew_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Thực hiện biến đổi logarit cho các cột có độ lệch cao (skewed)\n",
    "# Log transformation giúp giảm độ lệch và làm phân phối gần với phân phối chuẩn hơn\n",
    "# np.log1p = log(1 + x) để tránh log(0)\n",
    "for col in skew_columns.index.tolist():\n",
    "    data[col] = np.log1p(data[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform feature scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Chuẩn hóa dữ liệu (Feature Scaling)\n",
    "# StandardScaler chuyển đổi dữ liệu về mean=0 và std=1\n",
    "# Điều này quan trọng cho K-means vì thuật toán dựa trên khoảng cách\n",
    "sc = StandardScaler()\n",
    "data[float_columns] = sc.fit_transform(data[float_columns])\n",
    "\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the pairplot of the transformed and scaled features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_context('notebook')\n",
    "sns.pairplot(data[float_columns + ['color']], \n",
    "             hue='color', \n",
    "             hue_order=['white', 'red'],\n",
    "             palette={'red':red, 'white':'gray'});\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "*   Fit a K-means clustering model with two clusters.\n",
    "*   Examine the clusters by counting the number of red and white wines in each cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T01:59:09.017663Z",
     "start_time": "2017-03-19T21:59:08.896993-04:00"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "### BEGIN SOLUTION\n",
    "# BÀI TẬP 3: Áp dụng K-means clustering\n",
    "\n",
    "# Khởi tạo mô hình K-means với 2 clusters\n",
    "# n_clusters=2: phân thành 2 nhóm (có thể tương ứng với rượu đỏ và trắng)\n",
    "# random_state=42: để kết quả có thể tái tạo\n",
    "km = KMeans(n_clusters=2, random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình trên các thuộc tính hóa học\n",
    "km = km.fit(data[float_columns])\n",
    "\n",
    "# Dự đoán cluster cho mỗi điểm dữ liệu và lưu vào cột 'kmeans'\n",
    "data['kmeans'] = km.predict(data[float_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T01:59:09.332043Z",
     "start_time": "2017-03-19T21:59:09.315410-04:00"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "(data[['color','kmeans']]\n",
    " .groupby(['kmeans','color'])\n",
    " .size()\n",
    " .to_frame()\n",
    " .rename(columns={0:'number'}))\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "*   Now fit K-Means models with cluster values ranging from 1 to 20.\n",
    "*   For each model, store the number of clusters and the inertia value.\n",
    "*   Plot cluster number vs inertia. Does there appear to be an ideal cluster number?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T01:59:21.588328Z",
     "start_time": "2017-03-19T21:59:12.450288-04:00"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "# BÀI TẬP 4: Tìm số lượng cluster tối ưu bằng Elbow Method\n",
    "\n",
    "# Tạo danh sách để lưu kết quả của các mô hình\n",
    "km_list = list()\n",
    "\n",
    "# Thử với số cluster từ 1 đến 20\n",
    "for clust in range(1,21):\n",
    "    # Khởi tạo và huấn luyện K-means với số cluster = clust\n",
    "    km = KMeans(n_clusters=clust, random_state=42)\n",
    "    km = km.fit(data[float_columns])\n",
    "    \n",
    "    # Lưu số cluster, inertia (tổng khoảng cách bình phương đến centroid), và model\n",
    "    # Inertia thấp hơn = clustering tốt hơn, nhưng cần cân nhắc với số cluster\n",
    "    km_list.append(pd.Series({'clusters': clust, \n",
    "                              'inertia': km.inertia_,\n",
    "                              'model': km}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T01:59:21.775524Z",
     "start_time": "2017-03-19T21:59:21.589747-04:00"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "plot_data = (pd.concat(km_list, axis=1)\n",
    "             .T\n",
    "             [['clusters','inertia']]\n",
    "             .set_index('clusters'))\n",
    "\n",
    "ax = plot_data.plot(marker='o',ls='-')\n",
    "ax.set_xticks(range(0,21,2))\n",
    "ax.set_xlim(0,21)\n",
    "ax.set(xlabel='Cluster', ylabel='Inertia');\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "*   Fit an agglomerative clustering model with two clusters.\n",
    "*   Compare the results to those obtained by K-means with regards to wine color by reporting the number of red and white observations in each cluster for both K-means and agglomerative clustering.\n",
    "*   Visualize the dendrogram produced by agglomerative clustering. *Hint:* SciPy has a module called [`cluster.hierarchy`](https://docs.scipy.org/doc/scipy/reference/cluster.hierarchy.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2022-01-01#module-scipy.cluster.hierarchy) that contains the `linkage` and `dendrogram` functions required to create the linkage map and plot the resulting dendrogram.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T11:30:31.254165Z",
     "start_time": "2017-03-20T07:30:27.894864-04:00"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "### BEGIN SOLUTION\n",
    "# BÀI TẬP 5: Áp dụng Agglomerative Clustering (phân cụm phân cấp)\n",
    "\n",
    "# Khởi tạo Agglomerative Clustering với 2 clusters\n",
    "# n_clusters=2: số lượng cluster cuối cùng\n",
    "# linkage='ward': phương pháp liên kết minimizing variance trong cluster\n",
    "# compute_full_tree=True: tính toán cây phân cấp đầy đủ để vẽ dendrogram\n",
    "ag = AgglomerativeClustering(n_clusters=2, linkage='ward', compute_full_tree=True)\n",
    "ag = ag.fit(data[float_columns])\n",
    "\n",
    "# Dự đoán cluster và lưu vào cột 'agglom'\n",
    "data['agglom'] = ag.fit_predict(data[float_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that cluster assignment is arbitrary, the respective primary cluster numbers for red and white may not be identical to the ones below and also may not be the same for both K-means and agglomerative clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T11:46:08.938224Z",
     "start_time": "2017-03-20T07:46:08.924114-04:00"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# First, for Agglomerative Clustering:\n",
    "(data[['color','agglom','kmeans']]\n",
    " .groupby(['color','agglom'])\n",
    " .size()\n",
    " .to_frame()\n",
    " .rename(columns={0:'number'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Comparing with KMeans results:\n",
    "(data[['color','agglom','kmeans']]\n",
    " .groupby(['color','kmeans'])\n",
    " .size()\n",
    " .to_frame()\n",
    " .rename(columns={0:'number'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Comparing results:\n",
    "(data[['color','agglom','kmeans']]\n",
    " .groupby(['color','agglom','kmeans'])\n",
    " .size()\n",
    " .to_frame()\n",
    " .rename(columns={0:'number'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the cluster numbers are not identical, the clusters are very consistent within a single wine variety (red or white).\n",
    "\n",
    "And here is a plot of the dendrogram created from agglomerative clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T11:53:03.838928Z",
     "start_time": "2017-03-20T07:53:02.088506-04:00"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Import module hierarchy từ SciPy để vẽ dendrogram (sơ đồ cây phân cấp)\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "# Tạo ma trận linkage từ cây phân cụm đã tính\n",
    "# Z chứa thông tin về cách các cluster được gộp lại từng bước\n",
    "Z = hierarchy.linkage(ag.children_, method='ward')\n",
    "\n",
    "# Tạo figure với kích thước lớn để dễ quan sát\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "\n",
    "# Vẽ dendrogram (sơ đồ cây phân cấp)\n",
    "# orientation='top': cây phát triển từ dưới lên\n",
    "# p=30: chỉ hiển thị 30 nhánh cuối cùng (để đơn giản hóa)\n",
    "# truncate_mode='lastp': chỉ hiển thị p nhánh cuối\n",
    "# show_leaf_counts=True: hiển thị số lượng điểm dữ liệu trong mỗi nhánh\n",
    "den = hierarchy.dendrogram(Z, orientation='top', \n",
    "                           p=30, truncate_mode='lastp',\n",
    "                           show_leaf_counts=True, ax=ax)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "In this question, we are going to explore clustering as a form of feature engineering.\n",
    "\n",
    "*   Create a **binary** target variable `y`, denoting if the quality is greater than 7 or not.\n",
    "*   Create a variable called `X_with_kmeans` from `data`, by dropping the columns \"quality\", \"color\" and \"agglom\" from the dataset. Create `X_without_kmeans` from that by dropping \"kmeans\".\n",
    "*   For both datasets, using **[StratifiedShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2022-01-01)** with 10 splits, fit 10 Random Forest Classifiers and find the mean of the ROC-AUC scores from these 10 classifiers.\n",
    "*   Compare the average roc-auc scores for both models, the one using the KMeans cluster as a feature and the one that doesn't use it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "# BÀI TẬP 6: Sử dụng Clustering làm Feature Engineering\n",
    "\n",
    "# Tạo biến target nhị phân: 1 nếu chất lượng > 7, 0 nếu ngược lại\n",
    "y = (data['quality'] > 7).astype(int)\n",
    "\n",
    "# Tạo feature set có KMeans cluster\n",
    "X_with_kmeans = data.drop(['agglom', 'color', 'quality'], axis=1)\n",
    "\n",
    "# Tạo feature set không có KMeans cluster\n",
    "X_without_kmeans = X_with_kmeans.drop('kmeans', axis=1)\n",
    "\n",
    "# Sử dụng StratifiedShuffleSplit để chia dữ liệu thành 10 splits\n",
    "# Stratified đảm bảo tỷ lệ class được giữ nguyên trong mỗi split\n",
    "sss = StratifiedShuffleSplit(n_splits=10, random_state=6532)\n",
    "\n",
    "def get_avg_roc_10splits(estimator, X, y):\n",
    "    \"\"\"\n",
    "    Hàm tính ROC-AUC trung bình qua 10 splits\n",
    "    ROC-AUC đo lường khả năng phân loại của mô hình (0.5-1.0, càng cao càng tốt)\n",
    "    \"\"\"\n",
    "    roc_auc_list = []\n",
    "    # Lặp qua 10 splits\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        # Chia train/test set\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Huấn luyện mô hình\n",
    "        estimator.fit(X_train, y_train)\n",
    "        \n",
    "        # Dự đoán nhãn và xác suất\n",
    "        y_predicted = estimator.predict(X_test)\n",
    "        y_scored = estimator.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Tính ROC-AUC score\n",
    "        roc_auc_list.append(roc_auc_score(y_test, y_scored))\n",
    "    \n",
    "    # Trả về ROC-AUC trung bình\n",
    "    return np.mean(roc_auc_list)\n",
    "\n",
    "# Khởi tạo Random Forest Classifier\n",
    "estimator = RandomForestClassifier()\n",
    "\n",
    "# So sánh hiệu suất với và không có KMeans cluster feature\n",
    "roc_with_kmeans = get_avg_roc_10splits(estimator, X_with_kmeans, y)\n",
    "roc_without_kmeans = get_avg_roc_10splits(estimator, X_without_kmeans, y)\n",
    "\n",
    "print(\"Without kmeans cluster as input to Random Forest, roc-auc is \\\"{0}\\\"\".format(roc_without_kmeans))\n",
    "print(\"Using kmeans cluster as input to Random Forest, roc-auc is \\\"{0}\\\"\".format(roc_with_kmeans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now explore if the number of clusters have an effect in this improvement.\n",
    "\n",
    "*   Create the basis training set from `data` by restricting to float_columns.\n",
    "*   For $n = 1, \\ldots, 20$, fit a KMeans algorithim with $n$ clusters. **[One-hot encode]()** it and add it to the **basis** training set. Don't add it to the previous iteration.\n",
    "*   Fit 10 **Logistic Regression** models and compute the average roc-auc-score.\n",
    "*   Plot the average roc-auc scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Tạo tập dữ liệu cơ sở chỉ với các cột số thực\n",
    "X_basis = data[float_columns]\n",
    "sss = StratifiedShuffleSplit(n_splits=10, random_state=6532)\n",
    "\n",
    "def create_kmeans_columns(n):\n",
    "    \"\"\"\n",
    "    Hàm tạo features từ KMeans clustering với n clusters\n",
    "    One-hot encode các cluster labels để tạo features nhị phân\n",
    "    \"\"\"\n",
    "    # Fit KMeans với n clusters\n",
    "    km = KMeans(n_clusters=n)\n",
    "    km.fit(X_basis)\n",
    "    \n",
    "    # Dự đoán cluster cho mỗi điểm\n",
    "    km_col = pd.Series(km.predict(X_basis))\n",
    "    \n",
    "    # One-hot encode cluster labels\n",
    "    # Mỗi cluster trở thành một cột binary (0 hoặc 1)\n",
    "    km_cols = pd.get_dummies(km_col, prefix='kmeans_cluster')\n",
    "    \n",
    "    # Kết hợp features gốc với cluster features\n",
    "    return pd.concat([X_basis, km_cols], axis=1)\n",
    "\n",
    "# Sử dụng Logistic Regression thay vì Random Forest\n",
    "estimator = LogisticRegression()\n",
    "\n",
    "# Thử với số cluster từ 1 đến 20\n",
    "ns = range(1, 21)\n",
    "\n",
    "# Tính ROC-AUC trung bình cho mỗi số cluster\n",
    "roc_auc_list = [get_avg_roc_10splits(estimator, create_kmeans_columns(n), y)\n",
    "                for n in ns]\n",
    "\n",
    "# Vẽ biểu đồ kết quả\n",
    "ax = plt.axes()\n",
    "ax.plot(ns, roc_auc_list)\n",
    "ax.set(\n",
    "    xticklabels= ns,\n",
    "    xlabel='Number of clusters as features',\n",
    "    ylabel='Average ROC-AUC over 10 iterations',\n",
    "    title='KMeans + LogisticRegression'\n",
    ")\n",
    "ax.grid(True)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
